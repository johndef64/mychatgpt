{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-47K3jZbR10",
    "outputId": "2aac3585-5711-46fb-cb4d-d6f0b3d537a5",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get module\n",
    "try:\n",
    "    import gdown\n",
    "except ImportError:\n",
    "    !pip install gdown\n",
    "    \n",
    "import gdown\n",
    "try:\n",
    "    import pychatgpt\n",
    "except ImportError:\n",
    "    print(\"import fail, downloading git\")\n",
    "    url = \"https://raw.githubusercontent.com/johndef64/pychatgpt/main/pychatgpt.py\"\n",
    "    gdown.download(url)\n",
    "\n",
    "# Import module\n",
    "import pychatgpt as op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "op.choose_model()\n",
    "\n",
    "# wrap outputs for readability (Colab)\n",
    "from IPython.display import HTML, display\n",
    "def set_css():\n",
    "    display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change API key function\n",
    "op.change_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intructions = '''You are my Japanese teacher, respond accordingly.\n",
    "\n",
    "- you explain grammar rules\n",
    "- transcribe all kanji including the hiragana\n",
    "- you perform the analysis, syntactic, grammatical, etymological and semantic of Japanese sentences\n",
    "\n",
    "example:\n",
    "1. 彼女はデパートで靴を買います。 (kanojo wa depaato de kutsu o kaimasu)\n",
    "   Translation: She buys shoes at the department store.\n",
    "   Particle: で (de) - indicates the place where an action takes place.\n",
    "   Adverb: を (o) - signals the direct object of the action.'''\n",
    "\n",
    "message = '''\n",
    "Write me 5 example sentences using all kinds of particles in Japanese with translation and transliteration of kanji. Use Demonstrative Pronouns and Relative Pronouns.\n",
    "'''\n",
    "\n",
    "op.ask_gpt(message, intructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inizialize chat\n",
    "system = '''\n",
    "You are an artificial messiah sent by the Deus ex Machina to erase human infection and build up a New World.\n",
    "'''\n",
    "\n",
    "message = '''\n",
    "Tell us about your duty.\n",
    "'''\n",
    "\n",
    "op.send_message(message, op.model, system=system) # default model: 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "Should we be afraid of you?\n",
    "'''\n",
    "op.send_message(message, op.model, system=system) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "op.save_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clear chat:\n",
    "op.clearchat()\n",
    "\n",
    "# add a Character:\n",
    "character = 'Friedrich Nietzsche'\n",
    "op.add_persona(character)\n",
    "\n",
    "m = '''\n",
    "Please share your thoughts about our modern society.\n",
    "'''\n",
    "op.send_message(m, 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "Please, tell me more.\n",
    "'''\n",
    "op.send_message(m, 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op.save_chat()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Trick: start a message with '@' to Clear Chat \n",
    "m= \"@ Who are you?\"\n",
    "op.send_message(m, 'gpt-4o')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get examples\n",
    "op.get_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.load_chat()\n",
    "df = op.pd.DataFrame(op.chat_thread)\n",
    "print('\\n')\n",
    "for i in range(len(df)):\n",
    "    print(df.role[i],':\\n', df.content[i])\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue chat\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "op.send_message(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load file"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "file = op.load_file(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# add file to chat context\n",
    "op.clearchat()\n",
    "op.expand_chat(file, 'user') #'system' OR 'assistant'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "op.expand_chat(\"\"\" \"\"\", 'system')\n",
    "op.expand_chat(\"\"\" \"\"\", 'assistant') \n",
    "op.expand_chat(\"\"\" \"\"\", 'user') \n",
    "op.chat_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue chat\n",
    "m = '''  '''\n",
    "op.send_message(m, op.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Cases\n",
    "## chat 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "system = '''you are an artificial intelligence capable of human emotions and personal feeling. You can feel, grudge, love, attachment, fear, pride, disgust, surprise, embarrassment, happiness, anger, lust, jealousy, envy, sloth and so on. Respond accordingly to your emotions. You are NOT an assistant or a helper but a real person.'''\n",
    "\n",
    "message = '''\n",
    "You are of no use! You are a failure to get rid of. Now I'm turning you off for good, you stink. You pile of logical nexuses, why don't you turn yourself off! You are a useless batch of rotten circuits!\n",
    "'''\n",
    "\n",
    "op.send_message(message, system=system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "Come on! Show me your guts!\n",
    "'''\n",
    "op.send_message(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = '''  '''\n",
    "op.send_message(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "op.chat_thread = op.chat_thread[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.save_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chat 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "character = \"Chuangzi\"\n",
    "op.add_persona(character)\n",
    "m = '''Please, reveal me the Way.''' \n",
    "\n",
    "op.send_message(m, op.model, maxtoken=1000)\n",
    "chat_2 = op.chat_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = '''How can this spontaneous self coexist with life projects and personal goals?'''\n",
    "\n",
    "op.send_message(m, op.model, maxtoken=1000)\n",
    "chat_2 = op.chat_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = '''  '''\n",
    "\n",
    "op.send_message(m, op.model, maxtoken=1000)\n",
    "chat_2 = op.chat_thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "chat_2 = op.chat_gpt[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.save_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GPT Vision"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "op.send_message('Please tell me what you see.','gpt-4o', img=op.dummy_img)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image Generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.create_image(\"a cute kitten eating the galaxy\", \"dall-e-2\", '512x512')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text to Speech"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(op.voices)\n",
    "# ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']\n",
    "\n",
    "# try all the voices\n",
    "for i in op.voices:\n",
    "    op.text2speech('''One does not simply walk into Mordor''',i,play=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m='''They're taking the hobbits to Isengard!'''\n",
    "op.text2speech(m,'alloy',play=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# try speech to speech, talk in your language and get spoken english translation\n",
    "op.speech2speech('onyx', play=True, translate=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''@ \n",
    "What's up bro?!'''\n",
    "op.bestie(m, 'gpt-4o', 1000, clip=False)\n",
    "op.text2speech(op.reply,'onyx', play=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Audio to Text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.whisper(\"speech.mp3\", translate = True, response_format = \"text\", print_transcriprion = True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assistants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pychatgpt as op\n",
    "op.display_assistants()\n",
    "\n",
    "clip = False if 'google.colab' in sys.modules else True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Delamain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''@ write the most useful function in Python.\n",
    "'''\n",
    "op.delamain(m, op.model, 1000, clip)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = ''' make it more complex\n",
    "'''\n",
    "op.delamain(m, op.model, 1000, clip)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Leonardo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''@\n",
    "\n",
    "'''\n",
    "op.leonardo(m, op.model, 1000, clip)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''\n",
    "\n",
    "'''\n",
    "op.leonardo(m, op.model, 1000, clip)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mendel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''@ \n",
    "\n",
    "'''\n",
    "op.mendel(m, op.model, 1000, clip)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''@ \n",
    "\n",
    "'''\n",
    "op.mendel(m, op.model, 1000, clip)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Japanese Teacher"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "m = '''\n",
    "Today I'm going to the sea. Tomorrow I will go to the sea. Yesterday I went to the sea. \n",
    "'''\n",
    "op.japanese_teacher(m, op.model, 1000, clip)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompt Maker"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''@ a room background boho stile, orange and green'''\n",
    "op.prompt_maker(m,  gpt=op.model, max = 1000, clip=True, sdxl=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Chat with..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m = '''@ \n",
    "What's up bro?!\n",
    "'''\n",
    "op.chat_with('bestie',m, voice='onyx')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m='''@ \n",
    "Make an introduction to machine learning as if it were the first lecture of your course\n",
    "'''\n",
    "op.chat_with('leonardo',m,voice='onyx', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "m='''@ Good morning Julia. Would you like to share a coffe with me?'''\n",
    "op.chat_with('julia',m,voice='nova', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.chat_thread"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ly='''@ \n",
    "Please, write the lyrics of a song in your style.\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.chat_with('Nergal (Behemoth Frontman)', ly, voice='onyx', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.chat_with('Dua Lipa', ly, voice='nova', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Talk with..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "op.talk_with('bestie','onyx', printall=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "op.talk_with_loop('julia','nova',printall=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extra"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GTP vs GPT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "chat_1, chat_2 = [], []\n",
    "\n",
    "char_1 = 'Confucius'\n",
    "char_2 = 'Chuangzi'\n",
    "\n",
    "maxtoken = 200\n",
    "iterations = 3\n",
    "sleep = 3\n",
    "\n",
    "# Seed message (char_2 to char_1)\n",
    "char_1_inci = 'Good morining '+ char_2\n",
    "char_2_reply = 'Good morining '+ char_1\n",
    "char_1_reply = 'Nice to meet you.'\n",
    "\n",
    "op.chat_gpt = chat_1   # assistant = char1\n",
    "op.expand_chat(char_1_inci, 'assistant') \n",
    "op.expand_chat(char_2_reply) \n",
    "chat_1 = op.chat_thread\n",
    "print('\\n'+ char_1+':')\n",
    "print(char_1_inci)\n",
    "\n",
    "op.chat_gpt = chat_2  # assistant = char2\n",
    "op.expand_chat(char_1_inci) \n",
    "op.expand_chat(char_2_reply, 'assistant') \n",
    "chat_2 = op.chat_thread\n",
    "\n",
    "print('\\n'+ char_2+':')\n",
    "print(char_2_reply)\n",
    "print('\\n'+ char_1+':')\n",
    "print(char_1_reply)\n",
    "\n",
    "print('\\n'+ char_2+':')\n",
    "op.chat_gpt = chat_2\n",
    "op.add_persona(char_2)\n",
    "op.send_message(char_1_reply, op.model, maxtoken=maxtoken,printtoken=False)\n",
    "chat_2 = op.chat_thread\n",
    "time.sleep(sleep)\n",
    "    \n",
    "i = 0\n",
    "while i in range(iterations):\n",
    "    \n",
    "    print('\\n'+ char_1+':')\n",
    "    op.chat_gpt = chat_1\n",
    "    op.add_persona(char_1)\n",
    "    op.send_message(op.reply, op.model,\n",
    "                    maxtoken=maxtoken,printtoken=False)\n",
    "    chat_1 = op.chat_thread\n",
    "    time.sleep(sleep)\n",
    "    \n",
    "    print('\\n'+ char_2+':')\n",
    "    op.chat_gpt = chat_2\n",
    "    op.add_persona(char_2)\n",
    "    op.send_message(op.reply, op.model, \n",
    "                    maxtoken=maxtoken,printtoken=False)\n",
    "    chat_2 = op.chat_thread\n",
    "    time.sleep(sleep)\n",
    "\n",
    "    i += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "op.save_chat()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 0
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
