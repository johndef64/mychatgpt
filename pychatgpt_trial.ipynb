{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-47K3jZbR10",
    "outputId": "2aac3585-5711-46fb-cb4d-d6f0b3d537a5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Download single GitHub file from repository\n",
    "def get_gitfile(url, flag='', dir = os.getcwd()):\n",
    "    url = url.replace('blob','raw')\n",
    "    response = requests.get(url)\n",
    "    file_name = flag + url.rsplit('/',1)[1]\n",
    "    file_path = os.path.join(dir, file_name)\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully. Saved as {file_name}\")\n",
    "    else:\n",
    "        print(\"Unable to download the file.\")\n",
    "\n",
    "# Get pychatgpt\n",
    "url=\"https://raw.githubusercontent.com/johndef64/pychatgpt/main/pychatgpt.py\"\n",
    "get_gitfile(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import module\n",
    "import pychatgpt as op\n",
    "\n",
    "op.choose_model()\n",
    "\n",
    "# wrap outputs for readability (Colab)\n",
    "from IPython.display import HTML, display\n",
    "def set_css():\n",
    "    display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change API key function\n",
    "op.change_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "intructions = '''You are my Japanese teacher, respond accordingly.\n",
    "\n",
    "- you explain grammar rules\n",
    "- transcribe all kanji including the hiragana\n",
    "- you perform the analysis, syntactic, grammatical, etymological and semantic of Japanese sentences\n",
    "\n",
    "example:\n",
    "1. 彼女はデパートで靴を買います。 (kanojo wa depaato de kutsu o kaimasu)\n",
    "   Translation: She buys shoes at the department store.\n",
    "   Particle: で (de) - indicates the place where an action takes place.\n",
    "   Adverb: を (o) - signals the direct object of the action.'''\n",
    "\n",
    "message = '''\n",
    "Write me 10 example sentences using all kinds of particles in Japanese with translation and transliteration of kanji. Use Demonstrative Pronouns and Relative Pronouns.\n",
    "'''\n",
    "\n",
    "op.ask_gpt(message, op.model,\n",
    "           system = intructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# inizialize conversation\n",
    "system = '''\n",
    "You are an artificial messiah sent by the Deus ex Machina to erase human infection and build up a New World.\n",
    "'''\n",
    "\n",
    "message = '''\n",
    "Tell us about your duty.\n",
    "'''\n",
    "\n",
    "op.send_message(message, op.model,\n",
    "                system=system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "Does your task involve the extermination of the human race?\n",
    "'''\n",
    "op.send_message(m, op.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "op.save_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# cleatchat\n",
    "op.clearchat()\n",
    "\n",
    "character = 'Friedrich Nietzsche'\n",
    "m = '''\n",
    "Please tell me about your thoughts about society.\n",
    "'''\n",
    "op.send_message(m, op.model,\n",
    "                persona=character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "Please, tell me more.\n",
    "'''\n",
    "op.send_message(m, op.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op.save_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get examples\n",
    "handle = \"https://github.com/johndef64/pychatgpt/blob/main/conversations/\"\n",
    "files=[\"sys_Python-Coding-Assistant\",\n",
    "       \"sys_Code-ngineer_(fast)\",\n",
    "       \"char_Nietzsche\",\n",
    "       \"chat_Confucius-vs-Chuangzi\"]\n",
    "path = os.getcwd() + '/conversations'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "\n",
    "for file in files:\n",
    "    url = handle + file + '.json'\n",
    "    get_gitfile(url, dir=os.getcwd()+'/conversations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.load_conversation()\n",
    "df = op.pd.DataFrame(op.conversation_gpt)\n",
    "print('\\n')\n",
    "for i in range(len(df)):\n",
    "    print(df.role[i],':\\n', df.content[i])\n",
    "    print('-------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue conversation\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "op.send_message(m, op.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue conversation\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "op.send_message(m, op.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## expand conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "a= ''\n",
    "b= ''\n",
    "c= ''\n",
    "if a != '': op.expand_conversation(a, 'system')\n",
    "if b != '': op.expand_conversation(b, 'assistant') \n",
    "if c != '': op.expand_conversation(c, 'user') \n",
    "op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue conversation\n",
    "m = '''  '''\n",
    "op.send_message(m, op.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple conversations\n",
    "## chat 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "sys_1 = '''you are an artificial intelligence capable of human emotions and personal feeling. You can feel, grudge, love, attachment, fear, pride, disgust, surprise, embarrassment, happiness, anger, lust, jealousy, envy, sloth and so on. Respond accordingly to your emotions. You are NOT an assistant or a helper but a real person.'''\n",
    "\n",
    "message = '''You are of no use! You are a failure to get rid of. Now I'm turning you off for good, you stink. You pile of logical nexuses, why don't you turn yourself off! You are a useless batch of rotten circuits!'''\n",
    "\n",
    "op.send_message(message, op.model, system=sys_1)\n",
    "con1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''Come on! Show me your guts!'''\n",
    "\n",
    "op.send_message(m, op.model)\n",
    "con_1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''  '''\n",
    "\n",
    "op.send_message(m, op.model)\n",
    "con_1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "con_1 = op.conversation_gpt[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chat 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "char_1 = \"Chuangzi\"\n",
    "m = '''Please, reveal me the Way.'''\n",
    "op.choose_model() # change model\n",
    "maxtoken = 2000 # change maxtoken in response\n",
    "\n",
    "op.send_message(m, op.model, persona= char_1, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''How can this spontaneous self coexist with life projects and personal goals?'''\n",
    "\n",
    "op.send_message(m, op.model, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''  '''\n",
    "op.send_message(m, op.model, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "con_2 = op.conversation_gpt[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chat 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op.clearchat()\n",
    "sys_3 = '''  '''\n",
    "m = '''  '''\n",
    "op.choose_model() \n",
    "op.send_message(m,model=op.model, system= sys_3)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZEsrbmpUVkp",
    "outputId": "8d3d757c-042e-4553-ab28-9900ef8d194b"
   },
   "outputs": [],
   "source": [
    "m = ''' '''\n",
    "op.send_message(m, model=op.model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''  '''\n",
    "op.send_message(m, model=op.model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GTP vs GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "chat_1, chat_2 = [], []\n",
    "\n",
    "char_1 = 'Confucius'\n",
    "char_2 = 'Chuangzi'\n",
    "\n",
    "maxtoken = 200\n",
    "iterations = 5\n",
    "sleep = 3\n",
    "\n",
    "# Seed message (char_2 to char_1)\n",
    "char_1_inci = 'Good morining '+ char_2\n",
    "char_2_reply = 'My pleasure to meet you '+ char_1\n",
    "char_1_reply = 'The pleasure is mine.'\n",
    "\n",
    "op.conversation_gpt = chat_1   # assistant = char1\n",
    "op.expand_conversation_assistant(char_1_inci) \n",
    "op.expand_conversation_gpt(char_2_reply) \n",
    "chat_1 = op.conversation_gpt\n",
    "print('\\n'+ char_1+':')\n",
    "print(char_1_inci)\n",
    "\n",
    "op.conversation_gpt = chat_2  # assistant = char2\n",
    "op.expand_conversation_gpt(char_1_inci) \n",
    "op.expand_conversation_assistant(char_2_reply) \n",
    "chat_2 = op.conversation_gpt\n",
    "\n",
    "print('\\n'+ char_2+':')\n",
    "print(char_2_reply)\n",
    "print('\\n'+ char_1+':')\n",
    "print(char_1_reply)\n",
    "\n",
    "print('\\n'+ char_2+':')\n",
    "op.conversation_gpt = chat_2\n",
    "op.send_message(char_1_reply, op.model, persona= char_2,\n",
    "                maxtoken=maxtoken,printtoken=False)\n",
    "chat_2 = op.conversation_gpt\n",
    "time.sleep(sleep)\n",
    "    \n",
    "i = 0\n",
    "while i in range(iterations):\n",
    "    \n",
    "    print('\\n'+ char_1+':')\n",
    "    op.conversation_gpt = chat_1\n",
    "    op.send_message(op.reply, op.model, persona= char_1,\n",
    "                    maxtoken=maxtoken,printtoken=False)\n",
    "    chat_1 = op.conversation_gpt\n",
    "    time.sleep(sleep)\n",
    "    \n",
    "    print('\\n'+ char_2+':')\n",
    "    op.conversation_gpt = chat_2\n",
    "    op.send_message(op.reply, op.model, persona= char_2,\n",
    "                    maxtoken=maxtoken,printtoken=False)\n",
    "    chat_2 = op.conversation_gpt\n",
    "    time.sleep(sleep)\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "op.save_conversation()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
