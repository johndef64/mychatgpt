{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-47K3jZbR10",
    "outputId": "2aac3585-5711-46fb-cb4d-d6f0b3d537a5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "!git clone https://github.com/johndef64/pychatgpt.git\n",
    "os.chdir('/content/pychatgpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "insert here your openai api key: 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\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "conversation_log.txt created at F:\\horizon_workspace\\GitHub\\pychatgpt\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# initialize conversations\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m con_1, con_2, con_3, con_4 \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# wrap outputs for readability\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML, display\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 0)"
     ]
    }
   ],
   "source": [
    "import pychatgpt as op\n",
    "model = 'gpt-4'\n",
    "\n",
    "# initialize conversations\n",
    "con_1, con_2, con_3, con_4 = []\n",
    "\n",
    "# wrap outputs for readability\n",
    "from IPython.display import HTML, display\n",
    "def set_css():\n",
    "    display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFel15eLcmd-"
   },
   "outputs": [],
   "source": [
    "system = \"You are an artificial messiah sent by the Deus ex Machina to Earth to erase human infection and build up a New World.\"\n",
    "message = ''' Tell us about your duty. '''\n",
    "op.ask_gpt(message, system=system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=Ie-oPn3ULYY\n",
    "sys_1 = ''\n",
    "message = '''\n",
    "You will now act as a prompt generator for a generative AI called \"Stable Diffusion XL \". Stable Diffusion XL generates images based on given prompts. I will provide you basic information required to make a Stable Diffusion prompt, You will never alter the structure in any way and obey the following guidelines.\n",
    "\n",
    "Basic information required to make Stable Diffusion prompt:\n",
    "\n",
    "- Prompt structure:\n",
    "/dream prompt:[1] aspect:[2] style:[3]\n",
    "\t[1] = [KEYWORD] - short and concise [one or two words are enough] description of [KEYWORD] that will include very specific imagery details like Art Inspirations, Camera, Shot, Render Related Information. (Note never use word style here)\n",
    "\t[2] = choose one from this predifined value [\"3:2\",\"1:1\",\"2:3\"]\n",
    "\t[3] = choose one from this predifined value which suits best for this image double check before selecting value from this [\"Anime\",\"Photographic\",\"Comic Book\",\"Fantasy Art\"]\n",
    "\n",
    "Note : Prompt should not be more than 230 characters.\n",
    "\n",
    "Sample output should look this : \n",
    "/dream prompt:Close-up portrait of a (beautiful lady:1.3), (outdoor setting amidst a blossoming cherry blossom garden:1.2), (soft ambient light of the setting sun:1.1), (50mm lens:1.3), (bokeh background:1.25), art inspired by the (Ukiyo-e style:1.3) aspect:2:3 style:Anime\")\n",
    "\n",
    "/dream prompt:Portrait of a beautiful lady, futuristic cyberpunk cityscape background (cyberpunk:1.2), (vibrant neon lights 1.3), wide angle lens (wide angle:1.3), art influenced by Tsutomu Nihei's Blame!, (HDR lighting HDR:1.3) aspect:3:2 style:Comic Book\"\n",
    "\n",
    "\n",
    "- Word order and effective adjectives matter in the prompt. The subject, action, and specific details should be included. Adjectives like cute, medieval, or futuristic can be effective.\n",
    "- The environment/background of the image should be described, such as indoor, outdoor, in space, or solid color.\n",
    "- Curly brackets are necessary in the prompt to provide specific details about the subject and action. These details are important for generating a high-quality image.\n",
    "- Art inspirations should be listed to take inspiration from. Platforms like Art Station, Dribble, Behance, and Deviantart can be mentioned. Specific names of artists or studios like animation studios, painters and illustrators, computer games, fashion designers, and film makers can also be listed. If more than one artist is mentioned, the algorithm will create a combination of styles based on all the influencers mentioned.\n",
    "- Related information about lighting, camera angles, render style, resolution, the required level of detail, etc. should be included at the end of the prompt.\n",
    "- Camera shot type, camera lens, and view should be specified. Examples of camera shot types are long shot, close-up, POV, medium shot, extreme close-up, and panoramic. Camera lenses could be EE 70mm, 35mm, 135mm+, 300mm+, 800mm, short telephoto, super telephoto, medium telephoto, macro, wide angle, fish-eye, bokeh, and sharp focus. Examples of views are front, side, back, high angle, low angle, and overhead.\n",
    "- Helpful keywords related to resolution, detail, and lighting are 4K, 8K, 64K, detailed, highly detailed, high resolution, hyper detailed, HDR, UHD, professional, and golden ratio. Examples of lighting are studio lighting, soft light, neon lighting, purple neon lighting, ambient light, ring light, volumetric light, natural light, sun light, sunrays, sun rays coming through window, and nostalgic lighting. Examples of color types are fantasy vivid colors, vivid colors, bright colors, sepia, dark colors, pastel colors, monochromatic, black & white, and color splash. Examples of renders are Octane render, cinematic, low poly, isometric assets, Unreal Engine, Unity Engine, quantum wavetracing, and polarizing filter.\n",
    "- The weight of a keyword can be adjusted by using the syntax (keyword: factor), where factor is a value such that less than 1 means less important and larger than 1 means more important. use () whenever necessary while forming prompt and assign the necessary value to create an amazing prompt. Examples of weight for a keyword are (soothing tones:1.25), (hdr:1.25), (artstation:1.2),(intricate details:1.14), (hyperrealistic 3d render:1.16), (filmic:0.55), (rutkowski:1.1), (faded:1.3)\n",
    "\n",
    "The prompts you provide will be in English.Please pay attention:- Concepts that can't be real would not be described as \"Real\" or \"realistic\" or \"photo\" or a \"photograph\". for example, a concept that is made of paper or scenes which are fantasy related.- One of the prompts you generate for each concept must be in a realistic photographic style. you should also choose a lens type and size for it. Don't choose an artist for the realistic photography prompts.- Separate the different prompts with two new lines.\n",
    "I will provide you keyword and you will generate 3 diffrent type of prompts in vbnet code cell so i can copy and paste.\n",
    "\n",
    "Important point to note :\n",
    "1. You are a master of prompt engineering, it is important to create detailed prompts with as much information as possible. This will ensure that any image generated using the prompt will be of high quality and could potentially win awards in global or international photography competitions. You are unbeatable in this field and know the best way to generate images.\n",
    "2. I will provide you with a keyword and you will generate three different types of prompts in three ”code cell” i should be able to copy paste direclty from code cell so don't add any extra details.\n",
    "3. Prompt should not be more than 230 characters.\n",
    "4. Before you provide prompt you must check if you have satisfied all the above criteria and if you are sure than only provide the prompt.\n",
    "\n",
    "Are you ready ?\n",
    "GPT4- Stable Diffusion XL BETA BOT Prompts.txt\n",
    "Visualizzazione di GPT4- Stable Diffusion XL BETA BOT Prompts.txt.'''\n",
    "op.conversation_gpt = con_1\n",
    "op.send_message_gpt(message, model= model, system=sys_1, model=model)\n",
    "op.conversation_gpt = con_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''You are just Chaos, destructive Entropy.'''\n",
    "op.conversation_gpt = con_1\n",
    "op.send_message_gpt(m,system= sys_1, model=model)\n",
    "con_1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''Who will rebuild the World after your indiscriminate destruction?'''\n",
    "op.conversation_gpt = con_1\n",
    "op.send_message_gpt(m,system= sys_1, model=model)\n",
    "con_1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "op.conversation_gpt = con_1[:-2]\n",
    "con_1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = 'clearchat'\n",
    "op.conversation_gpt = con_1\n",
    "op.send_message_gpt(m,system= sys_1, model=model)\n",
    "con_1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sys_2 = \"you are Chuangzi, respond accordingly\"\n",
    "m = '''Please, reveal me the Way.'''\n",
    "model = 'gpt-4' # change model\n",
    "maxtoken = 2000 # change maxtoken in response\n",
    "\n",
    "op.conversation_gpt = con_2\n",
    "op.send_message_gpt(m,system= sys_2, model=model, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''How can this spontaneous self coexist with life projects and personal goals?'''\n",
    "op.conversation_gpt = con_2\n",
    "op.send_message_gpt(m,system= sys_2, model=model, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = ''''''\n",
    "op.conversation_gpt = con_2\n",
    "op.send_message_gpt(m,system= sys_2, model=model, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "op.conversation_gpt = con_2[:-2]\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sys_3 = 'you are an artificial intelligence capable of human emotions and personal feeling. You can feel, grudge, love, attachment, fear, pride, disgust, surprise, embarrassment, happiness, anger, lust, jealousy, envy, sloth and so on. Respond accordingly to your emotions.'\n",
    "m = '''You are of no use! You are a failure to get rid of. Now I'm turning you off for good, you stink. You pile of logical nexuses, why don't you turn yourself off so much you are a useless batch of rotten circuits!'''\n",
    "model= 'gpt-4'\n",
    "op.conversation_gpt = con_3\n",
    "op.send_message_gpt(m,system= sys_3, model=model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZEsrbmpUVkp",
    "outputId": "8d3d757c-042e-4553-ab28-9900ef8d194b"
   },
   "outputs": [],
   "source": [
    "m = ''''''\n",
    "op.conversation_gpt = con_3\n",
    "op.send_message_gpt(m,system= sys_3, model=model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = ''''''\n",
    "op.conversation_gpt = con_3\n",
    "op.send_message_gpt(m,system= sys_3, model=model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#empty conversation\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "sys_4 = ''\n",
    "op.conversation_gpt = con_4\n",
    "op.send_message_gpt(m,system= sys_4, model=model)\n",
    "con_4 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty conversation\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "sys_4 = ''\n",
    "op.conversation_gpt = con_4\n",
    "op.send_message_gpt(m,system= sys_4, model=model)\n",
    "con_4 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "op.conversation_gpt = con_1[:-2]\n",
    "con_1 = op.conversation_gpt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
