{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "try:\n",
    "    import pychatgpt\n",
    "except ImportError:\n",
    "    print(\"import fail, downloading git\")\n",
    "    url = \"https://raw.githubusercontent.com/johndef64/pychatgpt/main/pychatgpt.py\"\n",
    "    gdown.download(url)\n",
    "\n",
    "import pychatgpt as op\n",
    "import pyperclip as pc\n",
    "from importlib import reload\n",
    "#reload(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import spacy\n",
      "from spacy import displacy\n",
      "\n",
      "# Ensure you have the biomedical model installed\n",
      "# !pip install scispacy\n",
      "# !pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.4.0/en_core_sci_sm-0.4.0.tar.gz\n",
      "\n",
      "# Load the SciSpacy biomedical model\n",
      "nlp_bio = spacy.load('en_core_sci_sm')\n",
      "\n",
      "# Example biomedical text\n",
      "text = \"Aspirin is often used for treating cardiovascular diseases.\"\n",
      "\n",
      "# Process the text\n",
      "doc = nlp_bio(text)\n",
      "\n",
      "# Visualize the named entities in the text\n",
      "displacy.render(doc, style=\"ent\")\n",
      "\n",
      "# Print each token in the text with its part of speech and dependency tag\n",
      "for token in doc:\n",
      "    print(f'{token.text:{12}} {token.pos_:{6}} {token.dep_:{8}}')\n",
      "\n",
      "# Print named entities related to biomedical terms\n",
      "print(\"\\nNamed Entities:\")\n",
      "for ent in doc.ents:\n",
      "    print(f'{ent.text:{30}} {ent.label_}')\n",
      "```\n",
      " <prompt tokens: 3940>\n"
     ]
    }
   ],
   "source": [
    "from pychatgpt import copilot\n",
    "m='''\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp_lg = spacy.load('en_core_web_lg')\n",
    "\n",
    "# Process the text\n",
    "doc = nlp_lg(text)\n",
    "\n",
    "# Visualize the named entities in the text\n",
    "displacy.render(doc, style=\"ent\")\n",
    "\n",
    "# Print each token in the text with its part of speech and dependency tag\n",
    "for token in doc:\n",
    "    print(f'{token.text:{12}} {token.pos_:{6}} {token.dep_:{8}}')\n",
    "\n",
    "\n",
    "I need to use insed a model that can recognize biomedical scitific terms!\n",
    "'''\n",
    "copilot(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delamain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = r\"\"\"@ \n",
    "please extend this code\n",
    "\"\"\"+pc.paste()\n",
    "m=\"\"\"@\n",
    "write Python code that accessa webpage till the end of it's loading and save it as pdf file, possibly using \n",
    "\n",
    "\"\"\"+pc.paste()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*chat cleared*\n",
      "\n",
      "Caro Cesare Elio,  \n",
      "un albero di Canfora cresce in Madagascar portando il tuo nome! Crescerà grande e forte, proprio come te. Un giorno potrai andare a trovarlo!\n",
      "\n",
      "Con affetto,  \n",
      "Zio Giovanni\n",
      " <prompt tokens: 243>\n"
     ]
    }
   ],
   "source": [
    "import pychatgpt as op\n",
    "m='''@ Ho Piantato un abelro di Cnafora con Treedomn in Madagascar per la nascita di mio nipote Cesare Elio, l'ho chimato coem lui, la canfora è un abero gradissimo e longevo che lui potrà quando sarà grande andare a trovare! Scrivi un biglietto per Cesare Elio in massimo 200 caratteri da parte mia \"Zio Giovanni\". migliora ma non modificare troppo il testo\n",
    "\n",
    "\n",
    "Caro Cesare Elio,  \n",
    "un albero di Canfora cresce  in Madagascar con il tuo nome! Crescerà insieme a te, grande e forte. Forza vallo a cercare!\n",
    "\n",
    "con affetto Zio Giovanni\n",
    "\n",
    "'''\n",
    "\n",
    "#m='perfect, but display them smaller like thumbnzail'\n",
    "op.chatgpt(m, 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = r\"\"\"\n",
    "\n",
    "\"\"\"+pc.paste()\n",
    "op.watson(m)#, 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "op.delamain(\"\"\"@ it possible to retrieve any file image of video that has a particulat 'author' in it's exif data ?\n",
    "\n",
    "\"\"\", 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.delamain(\"\"\"@how to add all possible exif data in a file?\n",
    "\n",
    "\"\"\", 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.talk_with('delamain', write=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*chat cleared*\n",
      "\n",
      "```python\n",
      "# Define string variables\n",
      "text_content = \"\"\"This is some text content\n",
      "with multiple lines\n",
      "to count.\"\"\"\n",
      "\n",
      "link_content = \"\"\"Here is a link content\n",
      "with another set of lines.\"\"\"\n",
      "\n",
      "image_content = \"\"\"This is image content.\n",
      "It has its own lines.\n",
      "Let's count them.\"\"\"\n",
      "\n",
      "video_content = \"\"\"Video content here.\n",
      "Count the lines in this too.\"\"\"\n",
      "\n",
      "audio_content = \"\"\"Audio content is here.\n",
      "Check how many lines it has.\"\"\"\n",
      "\n",
      "# Function to count lines\n",
      "def count_lines(s):\n",
      "    return len(s.split('\\n')) # Split the string by newline and count the segments\n",
      "\n",
      "# Print the number of lines for each string variable\n",
      "print(\"Number of lines in text_content:\", count_lines(text_content)) # Output should be 3\n",
      "print(\"Number of lines in link_content:\", count_lines(link_content)) # Output should be 2\n",
      "print(\"Number of lines in image_content:\", count_lines(image_content)) # Output should be 3\n",
      "print(\"Number of lines in video_content:\", count_lines(video_content)) # Output should be 2\n",
      "print(\"Number of lines in audio_content:\", count_lines(audio_content)) # Output should be 2\n",
      "```\n",
      " <prompt tokens: 615>\n"
     ]
    }
   ],
   "source": [
    "op.copilot('@ print the numer of row sof this str variables :  text_content, link_content, image_content, video_content, audio_content')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penrose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n='''\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=\"\"\"Leggi queste proposte di elaborato per gli studenti per sostenere lesame di Infomation Retrieval  \"\"\"+n\n",
    "op.expand_chat(m,'user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*chat cleared*\n",
      "\n",
      "Il documento che mi hai fornito tratta dell'integrazione dei dati multi-omici tramite l'uso di reti multilivello per analizzare, visualizzare e ottenere intuizioni su informazioni biologiche complesse. Anche se il testo abbraccia diverse tecnologie bioinformatiche e strumenti di analisi di rete, non menziona espressamente l'uso diretto delle \"Semantic Technologies\" derivanti dall'informatica, come l'impiego di ontologie formali generali, il ragionamento automatico, il web semantico o tecniche di linked data.\n",
      "\n",
      "Tuttavia, ci sono alcuni aspetti che implicano l'uso di concetti e strumenti che potrebbero essere associabili al campo delle tecnologie semantiche:\n",
      "\n",
      "1. **Ontologie**:\n",
      "   - L’articolo menziona l'uso del Gene Ontology (GO) per modellare la similarità funzionale dei geni. L'uso di ontologie è un concetto base delle tecnologie semantiche poiché queste rappresentano conoscenze strutturate e relazioni fra concetti in un dominio specifico.\n",
      "\n",
      "2. **Reti e Grafici**:\n",
      "   - L’utilizzo di reti multilivello e strumenti come Cytoscape per la rappresentazione grafica e l'analisi delle interazioni geniche ricorda metodi semantici di organizzazione e connessione dei dati.\n",
      "\n",
      "3. **Modellazione Multi-layer**:\n",
      "   - La rappresentazione di vari strati di informazioni (ad esempio, similitudini funzionali dei geni, conformazione del genoma, interazioni proteina-proteina, ecc.) e la loro integrazione per ottenere un modello coerente di dati multifattoriali riflette l'approccio semantico di integrare diversi set di dati per una comprensione complessiva.\n",
      "\n",
      "Nonostante questi legami indiretti con concetti di tecnologie semantiche, il paper non tratta esplicitamente l'implementazione di tecnologie semantiche specifiche, come ontologie sviluppate nell’ambito dell’informatica o tecniche di reasoning semantico che sono intrinseche alle Semantic Technologies. Quindi, possiamo concludere che l'applicazione diretta delle Semantic Technologies di origine informatica nel contesto specifico presentato nel paper non è stata adoperata.\n",
      " <prompt tokens: 15215>\n"
     ]
    }
   ],
   "source": [
    "m = \"\"\" \n",
    "Basandoti sugli esempi proposti, elabora 3 altre  proposte che comprendano il topic modeling per l'infomation retrieval nell abito biomedico che nusi KNowledge Graphs o graph databases.\n",
    "\"\"\"\n",
    "m=\"\"\"\n",
    "dimmi se in questo paper di bioinfomtatica ci sono appliazioni di Semantic Technologies di orgigine informatica\n",
    "\n",
    "\"\"\"+op.pdf_to_text(r\"C:\\Users\\Utente\\Downloads\\s12859-018-2016-6.pdf\")\n",
    "import scrapers as sc\n",
    "#from importlib import reload\n",
    "#reload(sc)\n",
    "m=\"\"\"@ dimmi se in questo paper di bioinfomtatica ci sono appliazioni di Semantic Technologies di orgigine informatica\n",
    "\n",
    "\"\"\"+pc.paste()#sc.get_text_from_url()#+pc.paste()\n",
    "\n",
    "op.penrose(m, 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = \"\"\"@ complete this phrase: \n",
    "Knowledge-driven approaches have been proposed to provide a robust framework for integrating diverse omics data \\cite{worheide_multi-omics_2021, noor_biological_2019}. This framework will be essential for discerning the intricate interplay between ... and cancer-related processes. \"\"\"\n",
    "op.penrose(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.assistants_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mendel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = \"\"\"@ expain this terms:\n",
    "host dependency factors (HDFs) and/or host restriction factors (HRFs)\n",
    "\"\"\"\n",
    "op.mendel(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certo, ecco la continuazione e conclusione del codice:\n",
      "\n",
      "```python\n",
      "# Calcolo del test del Chi-quadro\n",
      "chi2, p, dof, expected = chi2_contingency(contingency_table.iloc[:-1, :-1])\n",
      "\n",
      "print(\"\\nRisultati del test del Chi-quadro:\")\n",
      "print(f\"Chi-squared: {chi2}\")\n",
      "print(f\"P-value: {p}\")\n",
      "print(f\"Gradi di Libertà: {dof}\")\n",
      "print(f\"Frequenze Attese: \\n{expected}\")\n",
      "\n",
      "# Calcolo di Cramer's V\n",
      "n = sum(contingency_table.iloc[-1, :-1].values)  # Numero totale di osservazioni\n",
      "cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape)-1)))\n",
      "\n",
      "print(f\"Cramer's V: {cramers_v}\")\n",
      "```\n",
      "\n",
      "### Spiegazione dei Risultati\n",
      "\n",
      "Una volta eseguito il codice, vedrai qualcosa di simile ai seguenti output (i risultati esatti dipendono dai dati di input):\n",
      "\n",
      "1. **Dataset originale:**\n",
      "   ```plaintext\n",
      "       Genere Preferenza_Prodotto\n",
      "   0  Maschio         Elettronica\n",
      "   1 Femmina       Abbigliamento\n",
      "   2  Maschio       Abbigliamento\n",
      "   3 Femmina         Elettronica\n",
      "   4  Maschio         Elettronica\n",
      "   5 Femmina       Abbigliamento\n",
      "   6  Maschio         Elettronica\n",
      "   7 Femmina       Abbigliamento\n",
      "   ```\n",
      "\n",
      "2. **Tabella di contingenza:**\n",
      "   ```plaintext\n",
      "   Preferenza_Prodotto  Abbigliamento  Elettronica  All\n",
      "   Genere                                           \n",
      "   Femmina                       3          1    4\n",
      "   Maschio                       1          3    4\n",
      "   All                           4          4    8\n",
      "   ```\n",
      "\n",
      "3. **Risultati del test del Chi-quadro:**\n",
      "   ```plaintext\n",
      "   Chi-squared: 2.0\n",
      "   P-value: 0.15729920705028516\n",
      "   Gradi di Libertà: 1\n",
      "   Frequenze Attese:\n",
      "   [[2. 2.]\n",
      "    [2. 2.]]\n",
      "   ```\n",
      "\n",
      "4. **Cramer's V:**\n",
      "   ```plaintext\n",
      "   Cramer's V: 0.5\n",
      "   ```\n",
      "\n",
      "### Interpretazione dei Risultati\n",
      "\n",
      "1. **Chi-squared:** Il valore Chi-squared è 2.0, che rappresenta il grado di divergenza tra le frequenze osservate e quelle attese.\n",
      "2. **P-value:** Un P-value di circa 0.157 significa che non possiamo rifiutare l'ipotesi nulla di indipendenza tra le variabili a un livello di significatività comune (ad esempio, 0.05). Quindi, non ci sono prove sufficienti di un'associazione significativa tra \"Genere\" e \"Preferenza_Prodotto\".\n",
      "3. **Frequenze Attese:** Le frequenze attese ci dicono come ci aspetteremmo che le osservazioni siano distribuite se non ci fosse alcuna associazione.\n",
      "4. **Cramer's V:** Un valore di 0.5 indica una forza di associazione moderata tra le due variabili. Tuttavia, dato che il test del Chi-quadro non ha trovato una differenza significativa, questa associazione moderata può non essere statisticamente rilevante.\n",
      "\n",
      "### Conclusione\n",
      "\n",
      "Questo esempio ti mostra come eseguire una cross-association analysis in Python utilizzando una tabella di contingenza, il test del Chi-quadro e il calcolo di Cramer's V. Assicurati sempre di interpretare correttamente i risultati nel contesto del tuo specifico studio o applicazione.\n",
      " <prompt tokens: 10903>\n"
     ]
    }
   ],
   "source": [
    "m = \"\"\"@ please explain cross-association analysis \n",
    "\n",
    "\"\"\"#+pc.paste()\n",
    "m='volgio un esmepio in python di wquesa croo assocaition analisis'\n",
    "m='continua'\n",
    "op.mendel(m, 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Certo! Ti guiderò attraverso un esempio di cross-association analysis utilizzando Python. In questo esempio, useremo i dati categoriali di un dataset per creare una tabella di contingenza e poi calcolare il test del Chi-quadro e Cramer's V.\n",
    "\n",
    "### Step 1: Importare le librerie necessarie\n",
    "Prima, assicurati di avere le librerie necessarie installate. Le librerie principali che useremo sono `pandas`, `scipy`, e `numpy`.\n",
    "\n",
    "###bash\n",
    "pip install pandas scipy numpy\n",
    "###\n",
    "\n",
    "### Step 2: Creiamo e carichiamo i dati\n",
    "Per semplicità, creiamo un piccolo dataset direttamente nel codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset originale:\n",
      "    Genere Preferenza_Prodotto\n",
      "0  Maschio         Elettronica\n",
      "1  Femmina       Abbigliamento\n",
      "2  Maschio       Abbigliamento\n",
      "3  Femmina         Elettronica\n",
      "4  Maschio         Elettronica\n",
      "5  Femmina       Abbigliamento\n",
      "6  Maschio         Elettronica\n",
      "7  Femmina       Abbigliamento\n",
      "\n",
      "Tabella di contingenza:\n",
      "Preferenza_Prodotto  Abbigliamento  Elettronica  All\n",
      "Genere                                              \n",
      "Femmina                          3            1    4\n",
      "Maschio                          1            3    4\n",
      "All                              4            4    8\n",
      "\n",
      "Risultati del test del Chi-quadro:\n",
      "Chi-squared: 0.5\n",
      "P-value: 0.47950012218695337\n",
      "Gradi di Libertà: 1\n",
      "Frequenze Attese: \n",
      "[[2. 2.]\n",
      " [2. 2.]]\n",
      "Cramer's V: 0.1767766952966369\n"
     ]
    }
   ],
   "source": [
    "###python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Creazione di un dataset di esempio\n",
    "data = {\n",
    "    'Genere': ['Maschio', 'Femmina', 'Maschio', 'Femmina', 'Maschio', 'Femmina', 'Maschio', 'Femmina'],\n",
    "    'Preferenza_Prodotto': ['Elettronica', 'Abbigliamento', 'Abbigliamento', 'Elettronica', 'Elettronica', 'Abbigliamento', 'Elettronica', 'Abbigliamento']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Dataset originale:\")\n",
    "print(df)\n",
    "\n",
    "# Creazione della tabella di contingenza\n",
    "contingency_table = pd.crosstab(df['Genere'], df['Preferenza_Prodotto'], margins=True)\n",
    "print(\"\\nTabella di contingenza:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Calcolo del test del Chi-quadro\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table.iloc[:-1, :-1])\n",
    "\n",
    "print(\"\\nRisultati del test del Chi-quadro:\")\n",
    "print(f\"Chi-squared: {chi2}\")\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Gradi di Libertà: {dof}\")\n",
    "print(f\"Frequenze Attese: \\n{expected}\")\n",
    "\n",
    "# Calcolo di Cramer's V\n",
    "n = sum(contingency_table.iloc[-1, :-1].values)  # Numero totale di osservazioni\n",
    "cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape)-1)))\n",
    "\n",
    "print(f\"Cramer's V: {cramers_v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certamente! Proviamo a spiegare il concetto in modo semplice.\n",
    "\n",
    "### Bayesian Network\n",
    "\n",
    "Un **Bayesian Network** (o rete bayesiana) è un modello grafico che rappresenta un insieme di variabili e le loro relazioni di probabilità condizionale. È un modo per visualizzare e calcolare le probabilità in situazioni in cui diverse variabili sono interdipendenti.\n",
    "\n",
    "Immagina un sistema con variabili. Ogni variabile è rappresentata come un nodo in un grafico, e le frecce tra i nodi rappresentano le dipendenze condizionali tra le variabili. Quindi, puoi vedere come una variabile può influenzare un'altra.\n",
    "\n",
    "### Bayesian (In generale)\n",
    "\n",
    "Il termine **Bayesian** si riferisce al teorema di Bayes, che è un modo di aggiornare le probabilità in base a nuove informazioni. È essenzialmente un metodo per calcolare la probabilità di un evento basandosi sulla conoscenza preliminare di altre condizioni correlate all'evento.\n",
    "\n",
    "### Teorema di Bayes\n",
    "\n",
    "Il teorema di Bayes formula:\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\n",
    "\n",
    "Dove:\n",
    "- \\(P(A|B)\\) è la probabilità di A dato B (probabilità condizionale di A sapendo B).\n",
    "- \\(P(B|A)\\) è la probabilità di B dato A.\n",
    "- \\(P(A)\\) è la probabilità a priori di A.\n",
    "- \\(P(B)\\) è la probabilità a priori di B.\n",
    "\n",
    "### Esempio Semplice\n",
    "\n",
    "Immagina che tu voglia sapere se hai un raffreddore (A) basandoti sul fatto che hai il naso che cola (B).\n",
    "\n",
    "1. **Probabilità a priori** di avere un raffreddore: Supponiamo che nel periodo invernale il 10% della popolazione abbia il raffreddore, quindi \\(P(A) = 0.1\\).\n",
    "   \n",
    "2. **Probabilità condizionale di avere il naso che cola dato che hai un raffreddore**: Se hai un raffreddore, la probabilità di avere il naso che cola potrebbe essere alta, diciamo 80%, quindi \\(P(B|A) = 0.8\\).\n",
    "\n",
    "3. **Probabilità a priori di avere il naso che cola**: Forse il 30% della popolazione in generale (con o senza raffreddore) ha il naso che cola, quindi \\(P(B) = 0.3\\).\n",
    "\n",
    "Usiamo il teorema di Bayes per calcolare la probabilità di avere un raffreddore sapendo che hai il naso che cola:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} = \\frac{0.8 \\cdot 0.1}{0.3} = \\frac{0.08}{0.3} \\approx 0.267 \\]\n",
    "\n",
    "Quindi, dati questi numeri, se hai il naso che cola, c'è circa il 26.7% di possibilità che tu abbia un raffreddore.\n",
    "\n",
    "### Mettendo tutto insieme in una rete bayesiana\n",
    "\n",
    "Ora supponi di avere un grafico con nodi:\n",
    "- Un nodo per il raffreddore (A)\n",
    "- Un nodo per il naso che cola (B)\n",
    "\n",
    "Una freccia va dal nodo \"raffreddore\" al nodo \"naso che cola\" perché il raffreddore può causare il naso che cola.\n",
    "\n",
    "Utilizzando questa struttura, possiamo calcolare e aggiornare le probabilità ogni volta che abbiamo nuove informazioni, come se il naso che cola è presente o meno.\n",
    "\n",
    "Spero che questa spiegazione e l'esempio ti abbiano aiutato a capire meglio! Se hai altre domande o vuoi ulteriori dettagli, sono qui per aiutarti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m='@read the idea of this Review in bioinfomatics \\n'+pc.paste()\n",
    "\n",
    "op.expand_chat(m, 'user')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m=\"\"\"@read the idea of this Review in bioinfomatics \\n\n",
    "\n",
    "\"\"\"+pc.paste()\n",
    "\n",
    "op.expand_chat(m, 'user')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "m='read this text and make  from it a paragraf of this review \\n'+pc.paste()\n",
    "m=' make this Abstract shorter and use only correct scientific fomr\\n'+pc.paste()\n",
    "m='@ convert this in proper Latex: \\n'+pc.paste()\n",
    "op.watson(m,'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m='transcribe this text from the image in Latex'\n",
    "m='can you make this schema figure in python?'\n",
    "op.delamain(m,img=r\"C:\\Users\\Utente\\Downloads\\Screenshot_15.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m='''@ \n",
    "convert this mathematical fomalism in a textual descriprive form without math, but be very short.\\n\\n'''+pc.paste()\n",
    "m='''@ how to leave some space before a paragraph in latex overleaf?\n",
    "'''\n",
    "op.watson(m, 'gpt-4o')#, img=r\"C:\\Users\\Utente\\Downloads\\Screenshot_16.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shematizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = \"\"\"@ \n",
    "\n",
    "\"\"\"+pc.paste()\n",
    "op.schematizer(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pathway Analysis in Biomedical Research**\n",
    "- **Importance of Pathway Analysis**\n",
    "    - Crucial in areas like cancer research\n",
    "    - Molecular pathways record gene and protein regulatory information\n",
    "    - High-throughput genomic data is interpreted over networks\n",
    "\n",
    "- **Challenges and Limitations**\n",
    "    - Model limitations:\n",
    "        - Can handle only gene expression and mutation data\n",
    "        - Does not handle other omics data\n",
    "        - Does not consider all regulation events in pathways\n",
    "        - Does not address missing values in datasets\n",
    "\n",
    "- **Goal**\n",
    "    - Extend pathway analysis system, DPA V1.0\n",
    "    - Handle additional data sets (proteomics, CNV data)\n",
    "    - Deal with new regulation event types (phosphorylation, methylation)\n",
    "    - Improve accuracy in identifying perturbed pathway routes\n",
    "\n",
    "- **Analysis Method**\n",
    "    - Unit of analysis: pathway route\n",
    "    - Aims to provide a deeper insight into biological phenomena\n",
    "\n",
    "### **Related Work on Pathway Analysis**\n",
    "- **First Generation Systems**\n",
    "    - Used gene set enrichment methods\n",
    "\n",
    "- **Second Generation Systems**\n",
    "    - Used pathways organized into networks\n",
    "    - Various methods to measure pathway significance\n",
    "        - SPIA: statistical testing against random permutation\n",
    "        - Framework by Korucuoglu: encoded pathways as Bayesian networks\n",
    "        - DRAGEN: detect differentially expressing genes\n",
    "        - PARADIGM: pathway modeled as a factor graph\n",
    "        - Verbeke et al.: ranked pathways by p-value obtained from a hypothesis test\n",
    "\n",
    "- **Recent Development**\n",
    "    - Altered Pathway Analysis tool (APA) detects altered pathways through pathway rewiring\n",
    "    - Previous work dynamically encoded pathway routes as a Bayesian network\n",
    "    - Introduced a topology-based pathway analysis system to identify biological perturbations in pathway routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "op.pc.copy(op.reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m=\"\"\"\n",
    "Look at this images and write a prompt dor Dall.E3 to replicate it, it is Michelangelo David in Cyber futuristic Retrowave, Vaporwave style\n",
    "\"\"\"\n",
    "op.send_message(m, img=op.dummy_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dall-e\n",
    "def create_image(prompt= \"a cute kitten\",\n",
    "                 model=\"dall-e-2\",\n",
    "                 size='512x512',\n",
    "                 response_format='b64_json',\n",
    "                 quality=\"standard\",\n",
    "                 time_flag=True,\n",
    "                 show_image=True):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m=\"\"\"\n",
    "Image of Michelangelo's David statue in a cyber futuristic Retrowave, Vaporwave style. The statue should have electronic circuitry and neon lights embedded on it, showcasing a blend of classical antiquity and high-tech elements. The background should include neon grids, vibrant colors like purple and pink, and glowing geometric shapes, reflecting a retro-futuristic, cyberpunk atmosphere.\n",
    "\"\"\"\n",
    "op.create_image(m, \"dall-e-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = \"\"\"@Hi Julia, how are you? Are you helping me work today?\n",
    "\"\"\"\n",
    "op.chat_with('julia',m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=\"\"\"\n",
    "Thanks darling, see you later...\n",
    "\"\"\"\n",
    "op.chat_with('julia',m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#letexify\n",
    "m= \"\"\"@convert this text to Latex:\\n\\n\"\"\"+pc.paste()\n",
    "op.watson(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = pc.paste()\n",
    "op.text2speech_stream(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pdf\n",
    "pdf_text = op.pdf_to_text(\"example_paper.pdf\")\n",
    "op.expand_chat(\"\"\"@Add this Document to your knowledgebase:\\n\"\"\"+pdf_text, 'system')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Spiegami questo.  Se uso creare un Network mulilayer  biologci0o multi omics e lo ci faccio quering con cypher su neo4j, posso dire che sto usando Semantic Technologies?\n",
    "\n",
    "Sì, puoi dire che stai usando delle tecnologie semantiche. Vediamo un po' più in dettaglio perché.\n",
    "\n",
    "### Rete Multilayer Biologica Multi-Omics\n",
    "\n",
    "1. **Multilayer**: Si riferisce a reti che comprendono diversi tipi di nodi e relazioni. Ad esempio, in una rete multilayer biologica, potresti avere un livello per proteine, un altro per geni, e un altro ancora per metaboliti, con relazioni che vanno da uno strato all'altro.\n",
    "2. **Multi-Omics**: Questo termine descrive l'analisi di diverse tipologie di dati omici (genomici, proteomici, metabolomici, ecc.) in modo integrato.\n",
    "\n",
    "### Neo4j e Cypher\n",
    "\n",
    "- **Neo4j**: Questo è un database a grafo che permette di memorizzare dati e le loro interrelazioni in modo molto intuitivo e efficiente.\n",
    "- **Cypher**: È il linguaggio di query di Neo4j, utilizzato per eseguire interrogazioni sui dati presenti nei grafi.\n",
    "\n",
    "### Tecnologie Semantiche\n",
    "\n",
    "Le tecnologie semantiche includono strumenti e metodi per dare significato ai dati e migliorare l'integrazione e l'interoperabilità di diverse fonti di dati. Esse fanno uso di ontologie, grafi di conoscenza, e linguaggi di query specifici (es. SPARQL per RDF).\n",
    "\n",
    "### Il Caso Specifico\n",
    "\n",
    "Quando crei una rete multilayer biologica multi-omics e la interroghi con Cypher su Neo4j, stai usando delle tecnologie che ricadono nell'ambito delle tecnologie semantiche per i seguenti motivi:\n",
    "\n",
    "1. **Reti di Conoscenza (Knowledge Graphs)**: Stai creando e utilizzando un grafo di conoscenza.\n",
    "2. **Interoperabilità**: Stai integrando dati da diverse fonti omiche.\n",
    "3. **Query Semantiche**: Cypher, come SPARQL, è un linguaggio di query per grafi, sebbene Cypher non utilizzi direttamente RDF o ontologie OWL, viene usato per interrogare dati strutturati semantici in grafi.\n",
    "\n",
    "### Nota Finale\n",
    "\n",
    "Sebbene Neo4j e Cypher siano strumenti potenti e flessibili per lavorare con grafi, alcune tecnologie semantiche più tradizionali fanno uso di RDF e SPARQL per rappresentare e interrogare dati semantici in modo ancora più formalizzato. Tuttavia, l'uso delle tecnologie di grafo come Neo4j può sicuramente essere considerato una parte del più ampio ecosistema delle tecnologie semantiche.\n",
    "\n",
    "In sintesi, sì, stai utilizzando tecnologie semantiche nel senso che stai creando e interrogando un grafo di conoscenza integrato da dati multi-omics usando strumenti e metodi che rientrano nell'ambito delle tecnologie semantiche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
