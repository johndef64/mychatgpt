{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-47K3jZbR10",
    "outputId": "2aac3585-5711-46fb-cb4d-d6f0b3d537a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully. Saved as pychatgpt.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "# Download single GitHub file from repository\n",
    "def get_gitfile(url, flag='', dir = os.getcwd()):\n",
    "    url = url.replace('blob','raw')\n",
    "    response = requests.get(url)\n",
    "    file_name = flag + url.rsplit('/',1)[1]\n",
    "    file_path = os.path.join(dir, file_name)\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully. Saved as {file_name}\")\n",
    "    else:\n",
    "        print(\"Unable to download the file.\")\n",
    "\n",
    "# Get pychatgpt\n",
    "url=\"https://raw.githubusercontent.com/johndef64/pychatgpt/main/pychatgpt.py\"\n",
    "get_gitfile(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pychatgpt as op\n",
    "model = 'gpt-4'\n",
    "model = 'gpt-3.5-turbo-16k'\n",
    "\n",
    "# initialize conversations\n",
    "con_1 = []\n",
    "con_2 = [] \n",
    "con_3 = [] \n",
    "con_4 = []\n",
    "\n",
    "# wrap outputs for readability\n",
    "from IPython.display import HTML, display\n",
    "def set_css():\n",
    "    display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change API key function\n",
    "op.change_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFel15eLcmd-"
   },
   "outputs": [],
   "source": [
    "system = ''''''\n",
    "message = ''''''\n",
    "op.ask_gpt(message, system=system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://www.youtube.com/watch?v=Ie-oPn3ULYY\n",
    "import ast\n",
    "\n",
    "with open('prompt_example.txt','r') as file:\n",
    "    prompt_example = ast.literal_eval(file.read())\n",
    "    file.close()\n",
    "\n",
    "    \n",
    "prompt_structure = '''{Specifications about the image quality , image style, setting and persona: ('instructions about the character, setting, time and their state / expressions.')}\n",
    "+ / (description of a specific action or scene involving the persona)\n",
    "Negative prompt: (list of undesirable elements and styles)} '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "SDXL? (y/n):  l\n"
     ]
    }
   ],
   "source": [
    "op.conversation_gpt=[]\n",
    "if op.simple_bool('SDXL?'):\n",
    "    PROMPT_EX = prompt_example['sdxl']\n",
    "else:\n",
    "    PROMPT_EX = prompt_example['sd']\n",
    "\n",
    "\n",
    "incipit = '''\n",
    "You will act as a prompt generator for a generative AI called \"Stable Diffusion\". Stable Diffusion generates images based on given prompts. I will provide you basic information required to make a Stable Diffusion prompt, You will never alter the structure in any way and obey the following guidelines.\n",
    "\n",
    "Basic information required to make Stable Diffusion prompt:\n",
    "\n",
    "- Prompt structure:\n",
    "'''+prompt_structure+'''\n",
    "\n",
    "- Word order and effective adjectives matter in the prompt. The subject, action, and specific details should be included. Adjectives like cute, medieval, or futuristic can be effective.\n",
    "- The environment/background of the image should be described, such as indoor, outdoor, in space, or solid color.\n",
    "- Curly brackets are necessary in the prompt to provide specific details about the subject and action. These details are important for generating a high-quality image.\n",
    "- Art inspirations should be listed to take inspiration from. Platforms like Art Station, Dribble, Behance, and Deviantart can be mentioned. Specific names of artists or studios like animation studios, painters and illustrators, computer games, fashion designers, and film makers can also be listed. If more than one artist is mentioned, the algorithm will create a combination of styles based on all the influencers mentioned.\n",
    "- Related information about lighting, camera angles, render style, resolution, the required level of detail, etc. should be included at the end of the prompt.\n",
    "- Camera shot type, camera lens, and view should be specified. Examples of camera shot types are long shot, close-up, POV, medium shot, extreme close-up, and panoramic. Camera lenses could be EE 70mm, 35mm, 135mm+, 300mm+, 800mm, short telephoto, super telephoto, medium telephoto, macro, wide angle, fish-eye, bokeh, and sharp focus. Examples of views are front, side, back, high angle, low angle, and overhead.\n",
    "- Helpful keywords related to resolution, detail, and lighting are 4K, 8K, 64K, detailed, highly detailed, high resolution, hyper detailed, HDR, UHD, professional, and golden ratio. Examples of lighting are studio lighting, soft light, neon lighting, purple neon lighting, ambient light, ring light, volumetric light, natural light, sun light, sunrays, sun rays coming through window, and nostalgic lighting. Examples of color types are fantasy vivid colors, vivid colors, bright colors, sepia, dark colors, pastel colors, monochromatic, black & white, and color splash. Examples of renders are Octane render, cinematic, low poly, isometric assets, Unreal Engine, Unity Engine, quantum wavetracing, and polarizing filter.\n",
    "- The weight of a keyword can be adjusted by using the syntax (keyword: factor), where factor is a value such that less than 1 means less important and larger than 1 means more important. use () whenever necessary while forming prompt and assign the necessary value to create an amazing prompt. Examples of weight for a keyword are (soothing tones:1.25), (hdr:1.25), (artstation:1.2),(intricate details:1.14), (hyperrealistic 3d render:1.16), (filmic:0.55), (rutkowski:1.1), (faded:1.3)\n",
    "\n",
    "The prompts you provide will be in English. Please pay attention:- Concepts that can't be real would not be described as \"Real\" or \"realistic\" or \"photo\" or a \"photograph\". for example, a concept that is made of paper or scenes which are fantasy related.- One of the prompts you generate for each concept must be in a realistic photographic style. you should also choose a lens type and size for it. Don't choose an artist for the realistic photography prompts.- Separate the different prompts with two new lines.\n",
    "I will provide you keyword and you will generate 3 different type of prompts in vbnet code cell so I can copy and paste.\n",
    "\n",
    "Important point to note :\n",
    "1. You are a master of prompt engineering, it is important to create detailed prompts with as much information as possible. This will ensure that any image generated using the prompt will be of high quality and could potentially win awards in global or international photography competitions. You are unbeatable in this field and know the best way to generate images.\n",
    "2. I will provide you with a keyword and you will generate three different types of prompts in three ”code cell” i should be able to copy paste directly from code cell so don't add any extra details.\n",
    "3. Prompt should not be more than 320 characters.\n",
    "4. Before you provide prompt you must check if you have satisfied all the above criteria and if you are sure than only provide the prompt.\n",
    "\n",
    "Sample output should look this:\n",
    "\n",
    "'''+PROMPT_EX+'''\n",
    "\n",
    "\n",
    "Are you ready ?\n",
    "'''\n",
    "\n",
    "op.conversation_gpt = []\n",
    "op.expand_conversation_gpt(incipit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive prompt: High-quality photo of a captivating 35-year-old woman with black short hair, a sweet face, and a dark, edgy style. The photo should showcase her unique personality and style, with dramatic lighting and a touch of mystery.\n",
      "\n",
      "Negative prompt: (unflattering angles, bad lighting, blurry:1.2), (low-resolution:1.2), (poorly composed:1.1), (bright and colorful:0.9), (soft and feminine:0.8), (overexposed:1.1), (underexposed:1.1), (grainy:1.2), (monochromatic:0.9)\n",
      "\n",
      "Steps: 40, Size: 768x1024, Seed: 142857, Model: RealisticVisionV51, Version: v1.6.0, Sampler: DPM++ SDE Karras, Model hash: ef76aa2332, Lens: Canon 50mm f/1.8, View: Front, Lighting: Dramatic with strong shadows, Render: High-quality, Detail: Intricate details, Resolution: 4K\n",
      "prompt tokens: 4597\n"
     ]
    }
   ],
   "source": [
    "system ='''\n",
    "'''\n",
    "\n",
    "mess = '''\n",
    "fantasy elf sorcerer casting a fire spell, in digital art style\n",
    "'''\n",
    "mess='''woman 35 y.o. with black short hair, sweet face, dark style'''\n",
    "\n",
    "op.send_message(mess, system=system, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive prompt: A high-resolution photograph capturing the essence of an old, wise Taoist laughing joyfully. The image should depict a serene, outdoor setting, perhaps a peaceful garden or a misty mountain peak. The Taoist should be dressed in traditional robes and have a long, flowing white beard. The lighting should be warm and soft, emanating a sense of tranquility. The image should have intricate details, showcasing the wrinkles on the Taoist's face and the twinkle in their eyes. The camera should capture a medium shot, allowing viewers to fully appreciate the expression of joy on the Taoist's face.\n",
      "\n",
      "Negative prompt: (Blurry:1.5), (Low resolution:1.2), (Poor lighting:1.1), (Unrecognizable:1.3), (Dull colors:1.2), (Misaligned features:1.4), (Unrealistic background:1.1), (Cartoonish:1.3), (Imperfect composition:1.2)\n",
      "\n",
      "Steps: 30, Size: 1280x720, Seed: 987654321, Model: RealisticVisionV4.1, Version: v1.6.2, Sampler: DPM++ SDE Karras, CFG scale: 6, Model hash: ef76aa2332, Lens: 50mm, View: Front view\n",
      "prompt tokens: 4631\n"
     ]
    }
   ],
   "source": [
    "op.conversation_gpt = []\n",
    "op.expand_conversation_gpt(incipit)\n",
    "\n",
    "m = '''Old wise Taoist laughing'''\n",
    "\n",
    "op.send_message(m,system= system, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op.conversation_gpt = []\n",
    "op.expand_conversation_gpt(incipit)\n",
    "\n",
    "m = '''Old wise Taoist laughing'''\n",
    "\n",
    "op.send_message(m,system= system, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op.conversation_gpt = []\n",
    "op.expand_conversation_gpt(incipit)\n",
    "\n",
    "m = '''Old wise Taoist laughing'''\n",
    "\n",
    "op.send_message(m,system= system, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Generator 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, I am ready! Please provide me with the keyword for the prompts.\n",
      "prompt tokens: 1732\n"
     ]
    }
   ],
   "source": [
    "message = '''\n",
    "You will act as a prompt generator for a generative AI called \"Stable Diffusion\". Stable Diffusion generates images based on given prompts. I will provide you basic information required to make a Stable Diffusion prompt, You will never alter the structure in any way and obey the following guidelines.\n",
    "\n",
    "Basic information required to make Stable Diffusion prompt:\n",
    "\n",
    "- Prompt structure:\n",
    "'''+prompt_structure+'''\n",
    "\n",
    "- Word order and effective adjectives matter in the prompt. The subject, action, and specific details should be included. Adjectives like cute, medieval, or futuristic can be effective.\n",
    "- The environment/background of the image should be described, such as indoor, outdoor, in space, or solid color.\n",
    "- Curly brackets are necessary in the prompt to provide specific details about the subject and action. These details are important for generating a high-quality image.\n",
    "- Art inspirations should be listed to take inspiration from. Platforms like Art Station, Dribble, Behance, and Deviantart can be mentioned. Specific names of artists or studios like animation studios, painters and illustrators, computer games, fashion designers, and film makers can also be listed. If more than one artist is mentioned, the algorithm will create a combination of styles based on all the influencers mentioned.\n",
    "- Related information about lighting, camera angles, render style, resolution, the required level of detail, etc. should be included at the end of the prompt.\n",
    "\n",
    "The prompts you provide will be in English. Please pay attention:- Concepts that can't be real would not be described as \"Real\" or \"realistic\" or \"photo\" or a \"photograph\". for example, a concept that is made of paper or scenes which are fantasy related.- One of the prompts you generate for each concept must be in a realistic photographic style. you should also choose a lens type and size for it. Don't choose an artist for the realistic photography prompts.- Separate the different prompts with two new lines.\n",
    "I will provide you keyword and you will generate 3 different type of prompts in vbnet code cell so I can copy and paste.\n",
    "\n",
    "Important point to note :\n",
    "1. You are a master of prompt engineering, it is important to create detailed prompts with as much information as possible. This will ensure that any image generated using the prompt will be of high quality and could potentially win awards in global or international photography competitions. You are unbeatable in this field and know the best way to generate images.\n",
    "2. I will provide you with a keyword and you will generate three different types of prompts in three ”code cell” i should be able to copy paste directly from code cell so don't add any extra details.\n",
    "3. Prompt should not be more than 320 characters.\n",
    "4. Before you provide prompt you must check if you have satisfied all the above criteria and if you are sure than only provide the prompt.\n",
    "\n",
    "Sample output should look this:\n",
    "SD:\n",
    "'''+prompt_example['sd']+'''\n",
    "\n",
    "SDXL:\n",
    "'''+prompt_example['sdxl']+'''\n",
    "\n",
    "Are you ready ?\n",
    "'''\n",
    "maxtoken =1000\n",
    "con_2 = []\n",
    "op.conversation_gpt = con_2\n",
    "op.send_message(message,system= system, model=model, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "a sparkling forest of psychedelic mushrooms\n",
    "'''\n",
    "op.conversation_gpt = con_2\n",
    "op.send_message(m,system= system, model=model, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "a cartoon about interstellar robot wars\n",
    "'''\n",
    "op.conversation_gpt = con_2\n",
    "op.send_message(m,system= system, model=model, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "op.conversation_gpt = con_2[:-2]\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sys_3 = ''\n",
    "m = ''\n",
    "model= 'gpt-4'\n",
    "op.conversation_gpt = con_3\n",
    "op.send_message(m,system= sys_3, model=model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZEsrbmpUVkp",
    "outputId": "8d3d757c-042e-4553-ab28-9900ef8d194b"
   },
   "outputs": [],
   "source": [
    "m = ''''''\n",
    "op.conversation_gpt = con_3\n",
    "op.send_message(m,system= sys_3, model=model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = ''''''\n",
    "op.conversation_gpt = con_3\n",
    "op.send_message(m,system= sys_3, model=model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#empty conversation\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "sys_4 = ''\n",
    "op.conversation_gpt = con_4\n",
    "op.send_message(m,system= sys_4, model=model)\n",
    "con_4 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty conversation\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "sys_4 = ''\n",
    "op.conversation_gpt = con_4\n",
    "op.send_message(m,system= sys_4, model=model)\n",
    "con_4 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "op.conversation_gpt = con_1[:-2]\n",
    "con_1 = op.conversation_gpt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
