{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-47K3jZbR10",
    "outputId": "2aac3585-5711-46fb-cb4d-d6f0b3d537a5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Download single GitHub file from repository\n",
    "def get_gitfile(url, flag='', dir = os.getcwd()):\n",
    "    url = url.replace('blob','raw')\n",
    "    response = requests.get(url)\n",
    "    file_name = flag + url.rsplit('/',1)[1]\n",
    "    file_path = os.path.join(dir, file_name)\n",
    "    if response.status_code == 200:\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully. Saved as {file_name}\")\n",
    "    else:\n",
    "        print(\"Unable to download the file.\")\n",
    "\n",
    "# Get pychatgpt\n",
    "url=\"https://raw.githubusercontent.com/johndef64/pychatgpt/main/pychatgpt.py\"\n",
    "get_gitfile(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "choose model: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Using gpt-3.5-turbo-16k model*\n"
     ]
    }
   ],
   "source": [
    "import pychatgpt as op\n",
    "models = ['gpt-3.5-turbo',     #0\n",
    "          'gpt-3.5-turbo-16k', #1\n",
    "          'gpt-4'              #2\n",
    "         ]             \n",
    "model = models[int(input('choose model:'))]\n",
    "print('*Using',model, 'model*')\n",
    "\n",
    "# wrap outputs for readability\n",
    "from IPython.display import HTML, display\n",
    "def set_css():\n",
    "    display(HTML('''\n",
    "  <style>\n",
    "    pre {\n",
    "        white-space: pre-wrap;\n",
    "    }\n",
    "  </style>\n",
    "  '''))\n",
    "get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change API key function\n",
    "op.change_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load file as variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "file = op.load_file(path)\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <style>\n",
       "    pre {\n",
       "        white-space: pre-wrap;\n",
       "    }\n",
       "  </style>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose file:\n",
      "0  sys_Genetic_Bioinf_Assistant\n",
      "1  sys_Python-Coding-Assistant\n",
      "2  sys_R-Coding-Assistant\n",
      "3  sys_code engineer (fast)\n",
      "4  sys_prompt engineer\n",
      " 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*conversation sys_Genetic_Bioinf_Assistant.json loaded*\n"
     ]
    }
   ],
   "source": [
    "op.load_conversation('sys_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# inizialize conversation\n",
    "system = '''\n",
    "\n",
    "'''\n",
    "#model = 'gpt-4'\n",
    "message = '''\n",
    "\n",
    "'''\n",
    "\n",
    "op.send_message(message,\n",
    "                    system=system,\n",
    "                    model= model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#op.load_conversation()\n",
    "#model = 'gpt-4'\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "op.send_message(m, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op.save_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# cleatchat\n",
    "op.send_message('clearchat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op.load_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op.conversation_gpt = []\n",
    "\n",
    "character = ''\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "op.send_message(m,\n",
    "                    persona=character,\n",
    "                    model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "\n",
    "'''\n",
    "op.send_message(m,\n",
    "                    persona=character,\n",
    "                    model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "op.save_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# cleatchat\n",
    "op.send_message('clearchat')\n",
    "print(op.conversation_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple conversations\n",
    "### conversation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# initialize conversations\n",
    "con_1, con_2, con_3, con4 = [],[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.conversation_gpt = con_1\n",
    "op.load_conversation()\n",
    "con_1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sys_1 = '''\n",
    "\n",
    "'''\n",
    "message = '''\n",
    "\n",
    "'''\n",
    "\n",
    "op.conversation_gpt = con_1\n",
    "op.send_message(message, system=sys_1, model=model)\n",
    "con1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "'''\n",
    "op.conversation_gpt = con_1\n",
    "op.send_message(m,system= sys_1, model=model)\n",
    "con_1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "\n",
    "'''\n",
    "op.conversation_gpt = con_1\n",
    "op.send_message(m,system= sys_1, model=model)\n",
    "con_1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "op.conversation_gpt = con_1[:-2]\n",
    "con_1 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op.conversation_gpt = con_2\n",
    "op.load_conversation()\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "char_1 = \"\"\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "model = 'gpt-4' # change model\n",
    "maxtoken = 2000 # change maxtoken in response\n",
    "\n",
    "op.conversation_gpt = con_2\n",
    "op.send_message(m,\n",
    "                persona= char_1, \n",
    "                model=model, \n",
    "                maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "\n",
    "'''\n",
    "op.conversation_gpt = con_2\n",
    "op.send_message(m,persona= char_1, model=model, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = ''''''\n",
    "op.conversation_gpt = con_2\n",
    "op.send_message(m,persona= char_1, model=model, maxtoken=maxtoken)\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "op.conversation_gpt = con_2[:-2]\n",
    "con_2 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sys_3 = ''\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "model= 'gpt-3.5-turbo-16k'\n",
    "op.conversation_gpt = con_3\n",
    "op.send_message(m,system= sys_3, model=model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZEsrbmpUVkp",
    "outputId": "8d3d757c-042e-4553-ab28-9900ef8d194b"
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "\n",
    "'''\n",
    "op.conversation_gpt = con_3\n",
    "op.send_message(m,system= sys_3, model=model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "m = '''\n",
    "\n",
    "'''\n",
    "op.conversation_gpt = con_3\n",
    "op.send_message(m,system= sys_3, model=model)\n",
    "con_3 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conversation 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#empty conversation\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "sys_4 = ''\n",
    "op.conversation_gpt = con_4\n",
    "op.send_message(m,system= sys_4, model=model)\n",
    "con_4 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#empty conversation\n",
    "m = '''\n",
    "\n",
    "'''\n",
    "sys_4 = ''\n",
    "op.conversation_gpt = con_4\n",
    "op.send_message(m,system= sys_4, model=model)\n",
    "con_4 = op.conversation_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last interaction\n",
    "op.conversation_gpt = con_1[:-2]\n",
    "con_1 = op.conversation_gpt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
